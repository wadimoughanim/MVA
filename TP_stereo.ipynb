{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wadimoughanim/MVA/blob/main/TP_stereo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wACpOuDijz6"
      },
      "source": [
        "# Stereo matching\n",
        "\n",
        "### Name: **WRITE YOUR NAME HERE**\n",
        "\n",
        "\n",
        "The objective of this practical session is to explore the main concepts in stereo matching by implementing two efficient stereo matching algorithms, namely: Semi Global Matching (SGM) [[Hirschmüller 2008](https://core.ac.uk/download/pdf/11134866.pdf)] and Patchmatch [[Barnes et al 2009](https://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/), [Bleyer et al 2011](http://dx.doi.org/10.5244/C.25.14)].\n",
        "\n",
        "We will first introduce the concept of Cost Volume, using the classic SD cost (squared differences) and the Census Transform. Disparities obtained from these costs are not particularly stable but locally aggregating costs allows reducing mismatches.\n",
        "To further improve the results on uniform areas a global method is needed. SGM is an approximate energy minimization algorithm based on Dynamic Programming that can also be seen as a filtering of the cost volume.\n",
        "\n",
        "SGM relies on the construction of a cost volume, which could be expensive to build for large disparity ranges. Several approaches allow narrowing down this cost while other methods avoid the problem. Patchmatch is one of these methods. Patchmatch uses a randomized search and exploits the local regularity of the scene in order to explore large disparity ranges.\n",
        "\n",
        "We will cover the following topics\n",
        "* Build a Cost Volume (CV) using SD and Census costs\n",
        "* Winner-Take-All disparity selection and CV filtering by aggregation\n",
        "* Left-Right consistency and median filtering\n",
        "* CV filtering by scanline optimization (Dynamic Programming)\n",
        "* CV filtering by Semi Global Matching\n",
        "* Randomized search with Patchmatch\n",
        "* Some data-driven stereo matching methods\n",
        "\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "To solve this practical session, answer the questions below. Then export the notebook with the answers using the menu option **File -> Download as -> Notebook (.ipynb)**. Then [submit the resulting file here](https://forms.gle/k6FSX2BrPix823dx6) by next week. You will receive an automatic acknowledgement of receipt.\n",
        "\n",
        "There are **13 questions** in the notebook and corresponding code cells to fill-in with the answers.\n",
        "\n",
        "The lecture notes associated to this session are in [notesC4.pdf](http://boucantrin.ovh.hw.ipol.im/static/facciolo/mvaisat/C4.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a0ztrECbijz_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "aaedcf6d-6e23-4892-c711-ada307fa3183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for srtm4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for MCCNN (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Setup code for the notebook\n",
        "\n",
        "# Execute code 'cells' like this by clicking on the 'Run'\n",
        "# button or by pressing [shift] + [Enter].\n",
        "\n",
        "# This cell only imports some python packages that will be\n",
        "# used below. It doesn't generate any output.\n",
        "\n",
        "# The following lines install the necessary packages in the colab environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    # download TP data and tools\n",
        "    !wget -q http://boucantrin.ovh.hw.ipol.im/static/facciolo/mvaisat/tp4.zip\n",
        "    !unzip -q -o tp4.zip\n",
        "\n",
        "    # install dependencies\n",
        "    !python -m pip -q install rpcm srtm4\n",
        "    !pip install -q 'ad @ git+https://github.com/DapengFeng/ad'\n",
        "    !python -m pip -q install  scipy geojson pyproj opencv-contrib-python~=4.8.0.76 rasterio ipyleaflet numba MCCNN\n",
        "\n",
        "\n",
        "except ImportError:\n",
        "    %matplotlib notebook\n",
        "    pass\n",
        "\n",
        "\n",
        "## Setup code for the notebook\n",
        "##\n",
        "# Autoreload external python modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# These are the main includes used through the notebook\n",
        "\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from numba import jit\n",
        "\n",
        "import pprint\n",
        "import ipyleaflet\n",
        "import json\n",
        "import geojson\n",
        "\n",
        "import utils          # IO tools\n",
        "import vistools       # display tools\n",
        "import rectification  # rectification tools\n",
        "import stereo         # stereo matching tools\n",
        "\n",
        "np.set_printoptions(linewidth=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze_Q8lspij0B"
      },
      "source": [
        "# A. Cost Volume Building and Filtering by Aggregation\n",
        "\n",
        "\n",
        "The function `stereo.costvolumeSD` builds the pixel-wise SD cost volume for a pair of images `im1`,`im2`.\n",
        "```python\n",
        "def costvolumeSD(im1, im2, dmin=-20, dmax=20):\n",
        "    '''\n",
        "    creates a Squared Difference stereo cost volume\n",
        "\n",
        "    Args:\n",
        "        im1,im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin,dmax: minimum and maximum disparity to be explored\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing cost volume of size [im1.shape[0], im1.shape[1], dmax+1 - dmin]\n",
        "    '''\n",
        "```\n",
        "\n",
        "It returns the cost volume indexed as `C[row, col, disp_idx]` where `disp_idx` $\\in [0, d_{max}-d_{min}]$. For color images, the mean of the squared differences over the channels is be computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhd3OrFHij0C"
      },
      "source": [
        "**Exercise 1.**\n",
        "Implement the (trivial) Winner Takes All `WTA` function that given a cost volume computes the image containing the index of the optimal disparity at each pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al3Hk2v8ij0C"
      },
      "outputs": [],
      "source": [
        "def WTA(CV):\n",
        "    \"\"\"\n",
        "    Compute the Winner Takes All (WTA) of the cost volume CV.\n",
        "\n",
        "    Args:\n",
        "        CV (np.array): 3D array containing a cost volume\n",
        "\n",
        "    Return:\n",
        "        2D array of disparity indices that minimise the cost volume\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lBlFyujij0D"
      },
      "source": [
        "The code below calls the `stereo.costvolumeSD` function to compute the cost volume for the `cones` image pair. Then, it displays an (x, d) slice of the cost volume (in log intensity). Finally it computes and shows\n",
        "the WTA disparity for the whole image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjRhVCgUij0D"
      },
      "outputs": [],
      "source": [
        "# read the images of the cones stereo pair\n",
        "im1 = utils.readGTIFF('data/im2.png')\n",
        "im2 = utils.readGTIFF('data/im6.png')\n",
        "dmin = -60\n",
        "dmax = 0\n",
        "\n",
        "vistools.display_gallery([im1, im2])\n",
        "\n",
        "# compute the cost volume\n",
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "\n",
        "# display slice\n",
        "vistools.display_imshow(np.log(1+CV[220, :, :].transpose()), cmap='gray', axis='tight', show=False)\n",
        "\n",
        "# overprint WTA plot\n",
        "df = np.argmin(CV[220, :, :], axis=1)\n",
        "plt.plot(df)\n",
        "plt.show()\n",
        "\n",
        "# show WTA disparity index\n",
        "vistools.display_imshow(WTA(CV)       , cmap='jet', title='WTA disparity indices', inline=True)\n",
        "\n",
        "# and the corresponding WTA disparity value\n",
        "vistools.display_imshow(WTA(CV) + dmin, cmap='jet', title='WTA disparity values', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHOncd1ij0E"
      },
      "source": [
        "The fact that the disparity is spatially regular permits to improve the above result.\n",
        "To do so we aggregate (i.e. **compute the mean**) of the costs on 2D windows (on the x, y plane).\n",
        "Usually a small window of $5\\times 5$ pixels suffices.\n",
        "This process amounts to computing the SSD (sum of squared differences) cost.\n",
        "\n",
        "We can also include a regularization in the `disparity` direction by difining a 3D window.\n",
        "\n",
        "**Exercise 2.** Implement the `aggregateCV` function below. This function filters the cost volume with a rectangular spatial window of size `win_w * win_h * win_d` and uniform `weight = 1 / (win_w * win_h * win_d)`. The function returns the filtered cost volume.\n",
        "\n",
        "**Hint:** Use `scipy.signal.convolve` to apply the convolution and set the parameter `mode='same'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0EC4V5Fij0E"
      },
      "outputs": [],
      "source": [
        "def aggregateCV(CV, win_w, win_h, win_d=1):\n",
        "    \"\"\"\n",
        "    Filter the cost volume with a 3D spatial-depth window of size\n",
        "    win_w * win_h * win_d and uniform weights 1 / (win_w * win_h * win_d).\n",
        "\n",
        "    Args:\n",
        "        CV: numpy array containing the cost volume\n",
        "        win_w, win_h, win_d (defaut=1): width, height and depth of the rectangular window\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the filtered cost volume\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    return CV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKfDtIdqij0F"
      },
      "source": [
        "The code below filters the cost volume produced in the previous exercise using your `aggregateCV` function.\n",
        "Then, it displays an (x, d) slice of the cost volume (in log intensity) and shows the WTA disparity for the whole image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIbpSaW9ij0F"
      },
      "outputs": [],
      "source": [
        "## Village\n",
        "# im1 = utils.readGTIFF('data/village2a.png')\n",
        "# im2 = utils.readGTIFF('data/village2b.png')\n",
        "# dmin, dmax = -30, 30\n",
        "\n",
        "# compute the SSD cost volume with 5x5 windows\n",
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "CV = aggregateCV(CV, 5, 5)\n",
        "\n",
        "# display slice\n",
        "vistools.display_imshow(np.log(1+CV[220].transpose()), cmap=\"gray\",\n",
        "                        axis=\"tight\", invert=True, show=False,\n",
        "                        title=\"Cost Volume (x, d) slice for y=220\")\n",
        "\n",
        "# WTA plot\n",
        "df = np.argmin(CV[220], axis=1)\n",
        "plt.plot(df)\n",
        "plt.show()\n",
        "\n",
        "# show WTA disparity\n",
        "vistools.display_imshow(WTA(CV)+dmin, cmap=\"jet\", title=\"WTA disparity\", inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXeNv6Lbij0G"
      },
      "source": [
        "# B. Census Transform\n",
        "\n",
        "The big limitation of the SSD cost is that it is not robust  to illumination changes or artifacts. The Hamming distance between Census Transforms (CT) is a very robust matching cost. The function `stereo.costvolumeCT` computes the CT of the two images, then uses them to compute the cost volume.\n",
        "\n",
        "The pair of satellite images `data/t0.tif`, `data/t1.tif` allow us to appreciate the robustness of CT. The objective of the following exercise is to compare the results obtained with the SD and CT cost volumes using the Cones image pair, and a pair of satellite images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Ur8Gxeij0G"
      },
      "source": [
        "**Exercise 3.** Complete the `ssd_vs_census` function below.\n",
        "The function produces the two disparity maps computed using the SD and CT costs.\n",
        "The parameters `cw`, `win_w` and `win_h` should be set to obtain the \"best\" results for each cost.\n",
        "The function displays the resulting disparity maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe58OZQpij0G"
      },
      "outputs": [],
      "source": [
        "def ssd_vs_census(im1, im2, dmin, dmax):\n",
        "    \"\"\"\n",
        "    Produce the \"best\" disparity maps we can get using SSD and CENSUS costs, aggregation, and WTA.\n",
        "\n",
        "    Args:\n",
        "        im1, im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin, dmax: minimum and maximum disparity to be explored\n",
        "\n",
        "    Returns:\n",
        "        happyness for your eyes\n",
        "    \"\"\"\n",
        "    # BEGIN SOLUTION\n",
        "    win_w = 5\n",
        "    win_h = 5\n",
        "    cw = 7\n",
        "    # END SOLUTION\n",
        "\n",
        "    # SSD\n",
        "    CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "    CV = aggregateCV(CV, win_w, win_h)\n",
        "    dSSD = WTA(CV)+dmin\n",
        "\n",
        "    # CENSUS\n",
        "    CV = stereo.costvolumeCT(im1, im2, dmin, dmax, cw)\n",
        "    CV = aggregateCV(CV, win_w, win_h)\n",
        "    dCT = WTA(CV)+dmin\n",
        "\n",
        "    f, ax = plt.subplots(1, 2)\n",
        "\n",
        "    ax[0].imshow(dSSD.squeeze(), cmap='jet')\n",
        "    ax[1].imshow(dCT.squeeze(), cmap='jet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7V5dKlWij0G"
      },
      "source": [
        "The code below calls your function for the `cones` and `satellite` pairs and display the computed disparity maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxDaDIjWij0H"
      },
      "outputs": [],
      "source": [
        "### load Cones pair ###\n",
        "im1 = utils.readGTIFF('data/im2.png')\n",
        "im2 = utils.readGTIFF('data/im6.png')\n",
        "dmin, dmax = -60, 0\n",
        "vistools.display_gallery([im1, im2])\n",
        "\n",
        "# compute and display the disparity maps\n",
        "ssd_vs_census(im1, im2, dmin, dmax)\n",
        "\n",
        "### load Satellite pair ###\n",
        "im1_sat = utils.readGTIFF('data/t0.tif')\n",
        "im2_sat = utils.readGTIFF('data/t1.tif')\n",
        "dmin_sat, dmax_sat = -30, 50\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(im1_sat),\n",
        "                          utils.simple_equalization_8bit(im2_sat)])\n",
        "\n",
        "# compute and display the disparity maps\n",
        "ssd_vs_census(im1_sat, im2_sat, dmin_sat, dmax_sat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-cLb9IYij0H"
      },
      "source": [
        "# C. Mismatch filtering: Left-Right and Speckle\n",
        "\n",
        "We can already put together our Block Matching algorithm (implemented below) `stereoBM(im1, im2, dmin, dmax, winh=5, winw=5, cost='sd', cw=5)` which given an image pair `im1`, `im2`, a disparity range, cost function, and a window size returns a disparity map.\n",
        "\n",
        "To remove the spurious matches in the disparity map we shall use the left-right consistency test and specke filtering, which are two of the most effective filtering methods.\n",
        "* The Left-Right Consistency test (to be implemented in function `leftright`) asks for the disparity maps computed from left-to-right and right-to-left to be inverse of each other. This verification imposes the uniqueness of the match. Let us denote by $L$ and $R$ the left and right images. Let $d_{L}$ be the disparity map from $L$ to $R$, that is $L(x) = R(x + d_{L}(x))$ and $d_{R}$ be the map from $R$ to $L$. The disparity at $x$ is **rejected** by the `leftright` test if\n",
        "$$\\lvert d_{R}([x + d_{L}(x)]) + d_{L}(x) \\rvert > \\tau,$$\n",
        "where $[\\cdot]$ is the rounding operator, and the threshold $\\tau$ is usually set to 1 pixel.\n",
        "\n",
        "*  The speckle filter (implemented in `stereo.specklefilter`) imposes the smoothness of the solution by removing  small connected disparity components that have a disparity inconsistent with their neighborhood.\n",
        "\n",
        "**Exercise 4.** Complete the implementation of the `leftright` function below. The function applies the left-right consistency test. It returns the filtered disparity map where the rejected pixels are set to `np.inf`.\n",
        "\n",
        "**Hint:** You may use the function `np.meshgrid` to generate two matrices with the `x` and `y` coordinates of all pixels of the disparity map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-xV-Pvfij0H"
      },
      "outputs": [],
      "source": [
        "def leftright(disp_L, disp_R, maxdiff=1):\n",
        "    \"\"\"\n",
        "    Filter the left disparity map by applying the left-right consistency test.\n",
        "\n",
        "        |disp_R(round(x + disp_L(x))) + disp_L(x)| <= maxdiff\n",
        "\n",
        "    Args:\n",
        "        disp_L, disp_R: numpy arrays containing the Left and Right disparity maps\n",
        "        maxdiff: threshold for the uniqueness constraint\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the disp_L disparity map with rejected pixels set to np.inf\n",
        "    \"\"\"\n",
        "    h, w = disp_L.shape\n",
        "    x, y = np.meshgrid(range(w), range(h))\n",
        "\n",
        "    # sanitize the disparity values\n",
        "    xx = np.round(np.clip(x + disp_L, 0, w - 1)).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "    # the binary matrix m is the resulf of the consistency test.\n",
        "    # here we use it to set the invalid pixels to infinity\n",
        "    out = disp_L.copy()\n",
        "    out[m] = np.inf\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXcwUHLuij0H"
      },
      "source": [
        "The cell below uses  your `leftright` function  to filter the disparity maps computed with `stereoBM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVz8gXbrij0H"
      },
      "outputs": [],
      "source": [
        "def stereoBM(im1, im2, dmin, dmax, winh=5, winw=5, cost='sd', cw=5, subpix_refine=False):\n",
        "    \"\"\"\n",
        "    Compute the disparity map from im1 to im2 using block matching with SSD and CENSUS costs.\n",
        "\n",
        "    Args:\n",
        "        im1, im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin, dmax (ints): minimum and maximum disparity to be explored\n",
        "        winh, winw (ints): aggregation window size (set to 1 to disable)\n",
        "        cost (str): type of cost volume can be: 'sd' or 'census'\n",
        "        cw (int): census window size, used when cost='census'\n",
        "        subpix_refine (bool): activates the Vfit subpixel refinement (default False)\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the disparity map\n",
        "\n",
        "    \"\"\"\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # create cost volume\n",
        "    if cost == 'sd':\n",
        "        CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "    else:\n",
        "        CV = stereo.costvolumeCT(im1, im2, dmin, dmax, cw)\n",
        "    print('t={:2.4f} done building CV'.format(time.time() - start_time))\n",
        "\n",
        "    # aggregate\n",
        "    CV = aggregateCV(CV, winh, winw)\n",
        "    print('t={:2.4f} done aggregating CV'.format(time.time() - start_time))\n",
        "\n",
        "    # WTA\n",
        "    if subpix_refine:\n",
        "        d, _ = stereo.VfitWTA(CV, np.nanargmin(CV, axis=2).astype(np.float32),\n",
        "                              np.nanmin(CV, axis=2).astype(np.float32))\n",
        "    else:\n",
        "        d = WTA(CV).astype(np.float32)\n",
        "\n",
        "    # map from disparity index to disparity value and return\n",
        "    return d + dmin\n",
        "\n",
        "\n",
        "## Let's reload the Cone images just in case\n",
        "im1 = utils.readGTIFF('data/im2.png')[:, :, 0]\n",
        "im2 = utils.readGTIFF('data/im6.png')[:, :, 0]\n",
        "dmin = -60\n",
        "dmax = 0\n",
        "\n",
        "# compute left and right dispariy maps\n",
        "win = 5\n",
        "dL = stereoBM(im1, im2, dmin, dmax, win, win, cost='census')\n",
        "dR = stereoBM(im2, im1, -dmax, -dmin, win, win, cost='census')\n",
        "vistools.display_imshow(dL, cmap='jet', range=[dmin, dmax], title=\"Left disparity map\", inline=True)\n",
        "vistools.display_imshow(dR, cmap='jet', range=[-dmax, -dmin], title=\"Right disparity map\", inline=True)\n",
        "\n",
        "# left-right\n",
        "dLR = leftright(dL, dR, 1)\n",
        "vistools.display_imshow(dLR, cmap='jet', range=[dmin, dmax], title=\"leftright consistency\", inline=True)\n",
        "\n",
        "# speckle\n",
        "%time dLRspeckle = stereo.specklefilter(dLR, area=50, th=1)\n",
        "vistools.display_imshow(dLRspeckle, cmap='jet', range=[dmin, dmax], title=\"leftright & specklefilter\", inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH4AHCk1ij0I"
      },
      "source": [
        "Finally let's define a shorthand function for applying these filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6LtXioBij0I"
      },
      "outputs": [],
      "source": [
        "def mismatchFiltering(dL, dR, area=50, tau=1):\n",
        "    \"\"\"\n",
        "    Apply left-right and speckle filters.\n",
        "\n",
        "    Args:\n",
        "        dL, dR (np.array): left and right disparity maps\n",
        "        area (int): minimum area parameter of the speckle filter\n",
        "        tau (int): maximum left-right disparity difference\n",
        "\n",
        "    Returns:\n",
        "        array containing a filtered version of the left disparity map, with rejected pixels set to infinity\n",
        "    \"\"\"\n",
        "    dLR = leftright(dL, dR, tau)\n",
        "    dLRspeckle = stereo.specklefilter(dLR, area=area, th=1)\n",
        "    return dLRspeckle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0kjbn6Zij0I"
      },
      "source": [
        "# D. 1D Cost Volume Filtering with Dynamic Programming\n",
        "\n",
        "Spatial regularity of the disparity map $D$ can be imposed by minimizing an energy along scanlines:\n",
        "\n",
        "$$ E(D) = \\sum_p C_p(D_p) + \\lambda \\sum_p \\lvert D_p - D_{p+1}\\rvert $$\n",
        "\n",
        "where $C$ is the cost volume and $p$ denotes the coordinates of a pixel along the scanline.\n",
        "\n",
        "Instead of just computing the optimal path, or labeling, $D$ (using the classic Viterbi algorithm), we shall implement a **forward-backward** algorithm, which computes the min-marginals at each pixel and for each disparity value. The optimal path is then extracted by point-wise WTA.\n",
        "\n",
        "First, we must implement a left-to-right Viterbi filtering `filterViterbi` (without backtracking) which solves the sequence of problems\n",
        "$$ L_+(p,d) = \\min_{D_1,\\dots  D_{p-1}} \\sum_{q=1}^{p} C_q(D_q) + \\lambda \\sum_{q=1}^{p-1} V(D_q, D_{q+1}) \\quad \\text{s.t.}\\quad D_p = d, $$\n",
        "and use it twice in the provided function `filterfwbw` to compute the min-marginals as in equation (17) of the notes\n",
        "$$S_p(d) = L_+(p,d) + L_-(p,d) - C_p(d)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbW193Fzij0I"
      },
      "source": [
        "**Exercise 5.**  Complete the implementation of the `filterViterbi` function below.\n",
        "The function filters the cost volume $C$ by computing\n",
        "$$L_+(p,d) = C_{p}(d) + \\min_{d'}(L_+(p-1, d') + \\lambda V (d, d')),$$\n",
        "and returns a numpy array containing the filtered costvolume.\n",
        "\n",
        "**Don't Panic** about efficiency while coding filterViterbi. After\n",
        "debugging we can accelerate it using the `numba.jit` compiler.\n",
        "\n",
        "<font color=\"red\">**Also answer to this Question.**</font> What is the complexity of filterViterbi with respect to the number\n",
        "of pixels M and the number of disparities L?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo974iUQij0J"
      },
      "outputs": [],
      "source": [
        "def filterViterbi(c, lam=8):\n",
        "    \"\"\"\n",
        "    Filter the cost volume by computing\n",
        "       L_+(p, d) =  C_{p}(d) + \\min_{d'}(L_+(p-1, d') +  \\lambda V(d, d'))\n",
        "       with   V(x, y) = |x - y|\n",
        "\n",
        "    Args:\n",
        "        cv: numpy array of shape [nodes M, disparities L] containing a cost volume slice\n",
        "        lam: lambda parameter of the energy\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the filtered costvolume slice\n",
        "    \"\"\"\n",
        "    sh = c.shape\n",
        "    num_nodes = sh[0]\n",
        "    num_disp  = sh[1]\n",
        "\n",
        "    L = c.copy().astype(np.float64)\n",
        "    for p in range(1, num_nodes): # loop over the nodes\n",
        "\n",
        "        # compute min path for each label of node i\n",
        "        for d in range(num_disp):\n",
        "            minL = np.inf\n",
        "\n",
        "            ### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "    return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS1jZo_vij0J"
      },
      "source": [
        ">>> WRITE YOUR ANSWER TO THE QUESTION HERE <<<"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDfvoSlnij0J"
      },
      "source": [
        "The code below defines the `filterfwbw` using your `filterViterbi` then applies it on line 220 of the SD cost volume (for the Cone pair)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSLGSihBij0J"
      },
      "outputs": [],
      "source": [
        "from numba import jit\n",
        "\n",
        "# compile the filterViterbi function with numba.jit\n",
        "#Viterbi = filterViterbi  # for DEBUGGING\n",
        "Viterbi = jit(filterViterbi,nopython=True)\n",
        "\n",
        "\n",
        "def filterfwbw(c, lam=8):\n",
        "    Viterbi = jit(filterViterbi,nopython=True)\n",
        "\n",
        "    fw = Viterbi(c[::1, :], lam=lam)\n",
        "    bw = Viterbi(c[::-1, :], lam=lam)\n",
        "    return fw + bw[::-1] - c[::1, :]\n",
        "\n",
        "\n",
        "### Let's reload the Cone pair just in case\n",
        "im1 = utils.readGTIFF('data/im2.png')[:, :, 0]\n",
        "im2 = utils.readGTIFF('data/im6.png')[:, :, 0]\n",
        "dmin = -60\n",
        "dmax = 0\n",
        "\n",
        "# compute the SD costvolume and extract the slice at line 220\n",
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "line = CV[220]\n",
        "\n",
        "# filter the slice\n",
        "# The lambda parameter depends on the range of values in the cost volume\n",
        "%time fline = filterfwbw(line, lam=1000)\n",
        "\n",
        "# display the slice\n",
        "vistools.display_imshow(np.log(1+fline.transpose()) , cmap='gray', axis='tight',\n",
        "                        invert=True, show=False, title=\"filtered slice\")\n",
        "# overprint the WTA solution on top of the costvolume\n",
        "d = np.argmin(line, axis=1)\n",
        "df = np.argmin(fline, axis=1)\n",
        "plt.plot(df)\n",
        "plt.show()\n",
        "\n",
        "# compare the WTA on the unfiltered costvolume with the filtered one\n",
        "plt.figure()\n",
        "plt.plot(d)\n",
        "plt.plot(df)\n",
        "plt.title(\"filtered vs unfiltered WTA\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzOal-Ypij0J"
      },
      "source": [
        "**Exercise 6.**  Complete the `filterViterbiV` function below.\n",
        "The function filters the cost volume $C$ by computing\n",
        "$$L_+(p,d) =  C_{p}(d) + \\min_{d'}(L_+(p-1,d') +  \\lambda V (d, d')) \\quad \\text{with}  \\quad\n",
        "V(d,d')  =\n",
        "\\left\\{\n",
        "\\begin{array}{ll}\n",
        "  0    &\\text{if } d  = d'  \\\\\n",
        "  P1  &\\text{if }  |d - d'|=1 \\\\\n",
        "  P2  &\\text{otherwise}\n",
        "\\end{array}\n",
        "\\right.,\n",
        "$$\n",
        "where the regularizer  parameters are set to $P1=1$ and $P2=4$.\n",
        "The function must return a numpy array containing the filtered costvolume slice.\n",
        "\n",
        "\n",
        "<font color=\"red\">**Also answer to this Question.**</font> What is the complexity of `filterViterbiV` with respect to the number\n",
        "of pixels M and the number of disparities L?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZsTN9-Hij0K"
      },
      "outputs": [],
      "source": [
        "def filterViterbiV(c, lam=8):\n",
        "    \"\"\"\n",
        "    The function filters the cost volume by computing\n",
        "       L_+(p, d) = C_{p}(d) + \\min_{d'}(L_+(p-1,d') + \\lambda V(d, d'))\n",
        "                       | 0 , if  x=y\n",
        "       with   V(x,y) = | P1, if |x-y|=1\n",
        "                       | P2, otherwise\n",
        "    and parameters P1=1 and P2=4.\n",
        "\n",
        "    Args:\n",
        "        cv: numpy array of shape [nodes M, disparities L] containing a cost volume slice\n",
        "        lam: lambda parameter of the energy\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the filtered costvolume slice\n",
        "    \"\"\"\n",
        "    P1 = 1.0\n",
        "    P2 = 4.0\n",
        "    sh = c.shape\n",
        "    num_nodes = sh[0]\n",
        "    num_disp  = sh[1]\n",
        "\n",
        "    L = c.copy().astype(np.float64)\n",
        "\n",
        "    for p in range(1, num_nodes): # loop over the nodes\n",
        "\n",
        "        minLim1 = np.min(L[p-1, :])  # precompute min of the previous node\n",
        "\n",
        "        # BEGIN SOLUTION\n",
        "        for d in range(num_disp):       # loop over the disparities\n",
        "            minL = lam * P2 + minLim1   # minLim1=0 when the previous node has been normalized\n",
        "            for dp in (d-1, d, d+1):\n",
        "                if dp >= 0 and dp < num_nodes:\n",
        "                    newL = L[p-1, dp] + lam * P1 * np.abs(d-dp)\n",
        "                    if minL > newL:\n",
        "                        minL = newL\n",
        "            L[p, d] += minL\n",
        "\n",
        "        # this normalization removes the min of the previous node\n",
        "        L[p, :] = L[p, :] - np.min(L[p, :])  # normalize (keeps values from growing too much)\n",
        "        # END SOLUTION\n",
        "\n",
        "    return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZ86N5mij0K"
      },
      "source": [
        ">>> WRITE YOUR ANSWER TO THE QUESTION HERE <<<"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdkHxIi1ij0K"
      },
      "source": [
        "The code below defines the `filterVfwbw` which applies your `filterViterbiV`\n",
        "twice to  compute the min-marginals as in equation (17) of the notes.\n",
        "Then applies it on line 220 of the SD cost volume (for the Cone pair)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AEAtJtAij0K"
      },
      "outputs": [],
      "source": [
        "from numba import jit\n",
        "\n",
        "# compile the filterViterbi function with numba.jit\n",
        "# Viterbi = filterViterbi  # for DEBUGGING\n",
        "ViterbiV = jit(filterViterbiV,nopython=True)\n",
        "\n",
        "\n",
        "def filterVfwbw(c, lam=8):\n",
        "    fw = ViterbiV(c[::1, :], lam=lam)\n",
        "    bw = ViterbiV(c[::-1, :], lam=lam)\n",
        "    return fw + bw[::-1] - c[::1, :]\n",
        "\n",
        "\n",
        "### Let's reload the Cone pair just in case\n",
        "im1 = utils.readGTIFF('data/im2.png')[:, :, 0]\n",
        "im2 = utils.readGTIFF('data/im6.png')[:, :, 0]\n",
        "dmin = -60\n",
        "dmax = 0\n",
        "\n",
        "# compute the SD costvolume and extract the slice at line 220\n",
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "line = CV[220]\n",
        "\n",
        "# filter the slice\n",
        "# The lambda parameter depends on the range of values in the cost volume\n",
        "%time fline = filterVfwbw(line, lam=1000)\n",
        "\n",
        "# display the slice\n",
        "print()\n",
        "vistools.display_imshow(np.log(1+np.abs(fline.transpose())), cmap='gray', axis='tight',\n",
        "                        invert=True, show=False, title=\"filtered slice\")\n",
        "# overprint the WTA solution on top of the costvolume\n",
        "d = np.argmin(line, axis=1)\n",
        "df = np.argmin(fline, axis=1)\n",
        "plt.plot(df)\n",
        "plt.show()\n",
        "\n",
        "# compare the WTA on the unfiltered costvolume with the filtered one\n",
        "plt.figure()\n",
        "plt.plot(d)\n",
        "plt.plot(df)\n",
        "plt.title(\"filtered vs unfiltered WTA\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPYXNAY3ij0K"
      },
      "source": [
        "Now let's assemble a scanline optimization algorithm in the function  `scanlinefilter` below by applying `filterVfwbw`, or your `filterViterbiV` twice, to all the scanlines of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAc711tPij0K"
      },
      "outputs": [],
      "source": [
        "def scanlinefilter(CV, lam=8):\n",
        "    \"\"\"\n",
        "    Scanline cost volume filtering using the forward-backward algorithm\n",
        "    using the truncated regularity term V (with parameters P1=1, P2=4)\n",
        "\n",
        "    Args:\n",
        "        CV: numpy array of size [width, height, disparity] containing the costvolume\n",
        "        lam: lambda regularity parameter\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the filtered costvolume\n",
        "    \"\"\"\n",
        "    ViterbiV = jit(filterViterbiV,nopython=True)\n",
        "\n",
        "    S = np.zeros(CV.shape)\n",
        "    for i in range(CV.shape[0]):\n",
        "        fw = ViterbiV(CV[i, :, :], lam=lam)\n",
        "        bw = ViterbiV(CV[i, ::-1, :], lam=lam)\n",
        "        S[i, :, :] = fw + bw[::-1] - CV[i, :, :]\n",
        "    return S"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR2vIFFDij0K"
      },
      "source": [
        "The code block below calls `scanlinefilter` and shows the WTA result for the cones image.\n",
        "\n",
        "**Exercise 7.** Adjust the value of the regularity parameter (lambda) in the code below to obtain a good result for the SD cost volumes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd_Bj8DSij0L"
      },
      "outputs": [],
      "source": [
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "\n",
        "THE_GOOD_LAMBDA = 1  ### CHANGE THIS TO GET A GOOD RESULT\n",
        "# BEGIN SOLUTION\n",
        "THE_GOOD_LAMBDA = 100\n",
        "# END SOLUTION\n",
        "\n",
        "# call scanlinefilter using the GOOD LAMBDA\n",
        "%time CV = scanlinefilter(CV, lam=THE_GOOD_LAMBDA)\n",
        "vistools.display_imshow(WTA(CV)+dmin, cmap='jet', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2mocAQij0L"
      },
      "source": [
        "As expected the result contains streaking artifacts because the scanlines are filtered independently.\n",
        "One way to remove the streaking artifacts is by post processing the cost volume\n",
        "with `aggregateCV` and then computing the WTA. Observe the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CLdJOh0ij0L"
      },
      "outputs": [],
      "source": [
        "# remove horizontal streaking artifacts by convolving with a vertical filter\n",
        "CV = aggregateCV(CV, 1, 5)\n",
        "vistools.display_imshow(WTA(CV)+dmin, cmap='jet', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtDvvd3uij0L"
      },
      "source": [
        "# E. Semi Global Matching\n",
        "\n",
        "\n",
        "In light of the previous result the next logical step would be to filter the cost volume along columns using dynamic programming too!  This is what SGM does, but it also includes diagonal filtering directions.\n",
        "\n",
        "<img src=\"https://qph.cf2.quoracdn.net/main-qimg-d8a62c27572f4d472d61e6300b87eeb5-lq\" alt=\"Logic\" width=\"150px\"/>\n",
        "\n",
        "\n",
        "**Exercise 8.** Complete the `sgmfilter` function below.\n",
        "The function is similar to `scanlinefilter` and includes the filtering along the columns.\n",
        "This corresponds to a 4-direction SGM.\n",
        "The function must return the filtered cost volume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VnYrV63ij0L"
      },
      "outputs": [],
      "source": [
        "def sgmfilter(CV, lam=8):\n",
        "    \"\"\"\n",
        "    SGM cost volume filtering along 4 directions\n",
        "    using the truncated regularity term V (with parameters P1=1, P2=4)\n",
        "\n",
        "    Args:\n",
        "        CV: numpy array of size [width, height, disparity] containing the costvolume\n",
        "        lam: lambda regularity parameter\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the filtered costvolume\n",
        "    \"\"\"\n",
        "    # compile the filterViterbiV function\n",
        "    ViterbiV = jit(filterViterbiV,nopython=True)\n",
        "\n",
        "    S = np.zeros(CV.shape)\n",
        "\n",
        "    for i in range(CV.shape[0]):\n",
        "        fw = ViterbiV(CV[i, :, :], lam)\n",
        "        bw = ViterbiV(CV[i, ::-1, :], lam)\n",
        "        S[i, :, :] += fw + bw[::-1]\n",
        "\n",
        "    for i in range(CV.shape[1]):\n",
        "\n",
        "        pass\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "    return S - 3*CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GEyH12Kij0L"
      },
      "source": [
        "The code below calls your `sgmfilter` function and applies it on the cones stereo pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2eWeIkwij0L"
      },
      "outputs": [],
      "source": [
        "CV = stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "\n",
        "# do 4-sgm\n",
        "%time CV = sgmfilter(CV, 300)       # SGM\n",
        "d = WTA(CV)                         # WTA\n",
        "\n",
        "if 0:               # optional 3x3 median filter\n",
        "    import scipy\n",
        "    d = scipy.signal.medfilt(d, kernel_size=(3, 3))\n",
        "\n",
        "vistools.display_imshow(d+dmin, cmap='jet', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW36i29Jij0M"
      },
      "source": [
        "## Wrap up SGM\n",
        "\n",
        "We can now write the function `stereoSGM`, analogous to `stereoBM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KvTFXawij0M"
      },
      "outputs": [],
      "source": [
        "def stereoSGM(im1, im2, dmin, dmax, lam=10, cost='census', cw=3, win=1, subpix_refine=False):\n",
        "    \"\"\"\n",
        "    Compute the disparity map from im1 to im2 using SGM.\n",
        "\n",
        "    Args:\n",
        "        im1, im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin, dmax: minimum and maximum disparity to be explored\n",
        "        lam:\n",
        "        cost: type of cost volume can be: 'sd' or 'census'\n",
        "        cw:  census window size, used when cost='census'\n",
        "        win: size of the square window with which the cost volume is filtered (set to 1 to disable)\n",
        "        subpix_refine: activates the Vfit subpixel refinement (default False)\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the disparity map\n",
        "    \"\"\"\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # generate the cost volume\n",
        "    if cost=='sd':\n",
        "        CV=stereo.costvolumeSD(im1, im2, dmin, dmax)\n",
        "    else:\n",
        "        CV=stereo.costvolumeCT(im1, im2, dmin, dmax, cw=cw)\n",
        "\n",
        "    print ('t={:2.4f} done building CV'.format(time.time() - start_time))\n",
        "    CV = sgmfilter(CV,lam)         # SGM\n",
        "\n",
        "    print ('t={:2.4f} done sgmfilter'.format(time.time() - start_time))\n",
        "\n",
        "    CV = aggregateCV(CV,win,win)\n",
        "\n",
        "    # WTA\n",
        "    if subpix_refine:\n",
        "        d,_ = stereo.VfitWTA(CV, np.nanargmin(CV,axis=2).astype(np.float32), np.nanmin(CV,axis=2).astype(np.float32))\n",
        "    else:\n",
        "        d = stereo.WTA(CV).astype(np.float32)\n",
        "\n",
        "    # map from disparity index to disparity value and return\n",
        "    return d+dmin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtBGq0piij0M"
      },
      "source": [
        "The code below applies the function `stereoSGM` to the satellite stereo pair `data/t0.tif`, `data/t1.tif` and then applies the `mismatchFiltering`.\n",
        "\n",
        "**Note:** from now on we are using the Census cost as the default matching cost.\n",
        "\n",
        "**Note 2:** the regularity parameter $\\lambda$ and the size of the census window `cw` may require some tweaking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2-ixT0Eij0M"
      },
      "outputs": [],
      "source": [
        "# im1 = utils.readGTIFF('data/im2.png')[:, :, 0]\n",
        "# im2 = utils.readGTIFF('data/im6.png')[:, :, 0]\n",
        "# dmin = -60\n",
        "# dmax = 0\n",
        "\n",
        "# im1_sat = utils.readGTIFF('data/rectified_ref.tif')[:, :, 0]\n",
        "# im2_sat = utils.readGTIFF('data/rectified_sec.tif')[:, :, 0]\n",
        "# dmin_sat, dmax_sat = -150, 100\n",
        "\n",
        "im1_sat = utils.readGTIFF('data/t0.tif')[:, :, 0]\n",
        "im2_sat = utils.readGTIFF('data/t1.tif')[:, :, 0]\n",
        "dmin_sat, dmax_sat = -30, 50\n",
        "\n",
        "# compute left and right disparity maps\n",
        "dL = stereoSGM(im1_sat, im2_sat, dmin_sat, dmax_sat, lam=20, cost='census', cw=7, win=3)\n",
        "dR = stereoSGM(im2_sat, im1_sat, -dmax_sat, -dmin_sat, lam=20, cost='census', cw=7, win=3)\n",
        "\n",
        "# apply mismatch filtering\n",
        "LRS = mismatchFiltering(dL, dR, 50)\n",
        "\n",
        "# display the result\n",
        "vistools.display_imshow(LRS, cmap='jet', inline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qruY1wKqij0M"
      },
      "outputs": [],
      "source": [
        "vistools.display_imshow(dR, cmap='jet', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJqBTizxij0M"
      },
      "source": [
        "# F. Randomized Search and Patchmatch\n",
        "\n",
        "\n",
        "The simplified patchmatch algorithm described in the notes consists of iterating two main steps:\n",
        "* random disparity search `randpass`,\n",
        "* disparity propagation (forward and backward) `fwpass` and `bwpass`.\n",
        "\n",
        "Each step updates the current disparity by proposing new disparities at each pixel,\n",
        "which are retained if they yield a lower matching cost.\n",
        "\n",
        "Our patchmatch implementation only works with the census distance (Hamming of census transformed images).\n",
        "\n",
        "We will start implementing a randomized disparity search algorithm (`randmatch`).\n",
        "A key component of this algorithm is the function `randpass` proposed in the block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKT_etjSij0M"
      },
      "source": [
        "**Exercise 9.** Complete the implementation of the `randpass` function.\n",
        "This function updates the current disparity map by randomly sampling new disparities for each pixel,\n",
        "and updating the  disparity and minimum cost if the cost is lower than the current one.\n",
        "The function receives the current offset and cost associated to each pixel as well as the new proposed offset.\n",
        "It must update the costs and offsets if appropriate and return them.\n",
        "\n",
        "**Hint:** Use the function `computeHamming(im1, im2, i, j, k, l)`\n",
        "to efficiently compute the matching cost (Hamming distance)\n",
        "between the position `im1[i, j]` and `im2[k, l]`.\n",
        "The function will be compiled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XonjHwZij0M"
      },
      "outputs": [],
      "source": [
        "@jit   ###  You can commet this line for debugging\n",
        "def randpass(off, cost, randoff, im1, im2):\n",
        "    '''\n",
        "    This function updates the current disparity map by randomly sampling new disparities for each pixel\n",
        "    and updating the  disparity and minimum cost if the cost is lower than the current one.\n",
        "\n",
        "    Args:\n",
        "        im1,im2: numpy arrays containing the census transformed images of the pair\n",
        "        off and cost: are numpy arrays containing the current offsets (or disparities) and costs for each pixel.\n",
        "        randoff: is a set of new offsets to be tested for each pixel\n",
        "\n",
        "    Returns:\n",
        "        numpy two arrays containing the disparity map and\n",
        "        the minimum matching costs at each pixel\n",
        "    '''\n",
        "    H,W,C = im1.shape\n",
        "\n",
        "\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            newoff = randoff[i,j]\n",
        "            if j+newoff >= 0 and j+newoff < W:\n",
        "\n",
        "                newcost = stereo.computeHamming(im1,im2,i,j,i,j+newoff)\n",
        "\n",
        "                ### YOUR CODE HERE ###\n",
        "\n",
        "                # BEGIN SOLUTION\n",
        "                if newcost < cost[i,j]:\n",
        "                    off[i,j]  = newoff\n",
        "                    cost[i,j] = newcost\n",
        "\n",
        "                #END SOLUTION\n",
        "\n",
        "    return off, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47hWBGbHij0N"
      },
      "source": [
        "The code below defines and tests the `randmatch` algorithm (which uses your `randpass` function).\n",
        "The algorithm will run 100 iterations, hence 100 disparities per pixel will be sampled.\n",
        "\n",
        "**The input images are cropped to facilitate the debugging of the `randpass` function. When  compiled with @jit you can remove the crop.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VnDhr3Qij0N"
      },
      "outputs": [],
      "source": [
        "def randmatch (im1,im2,dmin,dmax,cw=7,it=5):\n",
        "    '''\n",
        "    computes the disparity map from im1 to im2 by randomly\n",
        "    sampling disparities and using the census cost\n",
        "\n",
        "    Args:\n",
        "        im1,im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin,dmax: minimum and maximum disparity to be explored\n",
        "        cw: census window size, used when cost='census'\n",
        "        it: number or random sampling iterations\n",
        "    Returns:\n",
        "        numpy two arrays containing the disparity map and\n",
        "        the minimum matching costs at each pixel\n",
        "    '''\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # apply census transform to both images\n",
        "    im1 = stereo.censustransform(im1,cw)\n",
        "    im2 = stereo.censustransform(im2,cw)\n",
        "    if im1.ndim == 2:   # computeHamming expects 3 dimensions\n",
        "        im1 = np.expand_dims(im1,2)\n",
        "        im2 = np.expand_dims(im2,2)\n",
        "    print ('t={:2.4f} done computing transforms {}, '.format(time.time() - start_time, im1.shape))\n",
        "\n",
        "    H,W,C = im1.shape\n",
        "    off    = np.zeros((H,W),dtype=np.float64)\n",
        "    cost   = np.zeros((H,W),dtype=np.float64) + np.Infinity\n",
        "\n",
        "    # do random search iterating it times\n",
        "    for it in range(it):\n",
        "        newoff = np.random.randint(dmin,dmax,size=(H,W))\n",
        "        off, cost = randpass(off,cost,newoff,im1, im2)\n",
        "        # ###\n",
        "        # ###\n",
        "    print ('t={:2.4f} done running patchmatch {}, '.format(time.time() - start_time, im1.shape))\n",
        "\n",
        "    return off, cost\n",
        "\n",
        "\n",
        "# We're using a smaller image for debugging in case of no @jit\n",
        "# remove the 100 to get the full image\n",
        "im1 = utils.readGTIFF('data/im2.png')[:,:100,0]\n",
        "im2 = utils.readGTIFF('data/im6.png')[:,:100,0]\n",
        "dmin,dmax = -60, 0\n",
        "\n",
        "off,cost = randmatch(im1,im2,dmin, dmax,it=100)\n",
        "\n",
        "vistools.display_imshow(off, cmap='jet',range=[dmin,dmax], inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRcV4bqEij0N"
      },
      "source": [
        "To complete the `patchmatch` implementation we only need to implement the forward and backward propagation functions `fwpass` and `bwpass`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1h9KIVvij0N"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def fwbwpass(off,cost, im1,im2,  backward=False):\n",
        "    '''\n",
        "    These function updates the current disparity map (off) by propagating the disparities in lexicogaphic\n",
        "    and inverse lexicographic order respectively. This is done by testing the offsets of the\n",
        "    two neighboring nodes (up and left for lexicographic order) at the current pixel\n",
        "    and updating the  disparity and minimum cost if the cost is lower than the current one.\n",
        "\n",
        "    Args:\n",
        "        im1,im2: numpy arrays containing the census transformed images of the pair\n",
        "        off and cost: are numpy arrays containing the current offsets (or disparities) and costs for each pixel.\n",
        "        randoff: is a set of new offsets to be tested for each pixel\n",
        "        backward: boolean that switchs to backward pass\n",
        "\n",
        "    Returns:\n",
        "        numpy two arrays containing the disparity map and\n",
        "        the minimum matching costs at each pixel\n",
        "    '''\n",
        "    H,W,C = im1.shape\n",
        "\n",
        "    # configure the traversals\n",
        "    sx, ex, dd = 1,W,1\n",
        "    sy, ey, dd = 1,H,1\n",
        "\n",
        "    if backward:\n",
        "        sx, ex, dd = W-2,-1,-1\n",
        "        sy, ey, dd = H-2,-1,-1\n",
        "\n",
        "    for i in range(sy,ey,dd):\n",
        "        for j in range(sx,ex,dd):\n",
        "            for newoff in (off[i-dd,j], off[i,j-dd]):\n",
        "                if j+newoff >= 0 and j+newoff < W:\n",
        "                    newc = stereo.computeHamming(im1,im2,i,j,i,j+newoff)\n",
        "                    if newc < cost[i,j]:\n",
        "                        off[i,j]  = newoff\n",
        "                        cost[i,j] = newc\n",
        "    return off,cost\n",
        "\n",
        "\n",
        "## @jit\n",
        "def fwpass(off,cost, im1,im2):\n",
        "    '''\n",
        "    see  fwbwpass\n",
        "    '''\n",
        "    return fwbwpass(off,cost, im1,im2,  False)\n",
        "\n",
        "\n",
        "## @jit\n",
        "def bwpass(off,cost, im1,im2):\n",
        "    '''\n",
        "    see  fwbwpass\n",
        "    '''\n",
        "    return fwbwpass(off,cost, im1,im2,  True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kppw_SIwij0N"
      },
      "source": [
        "**Exercise 10.** Complete the `patchmatch` implementation below by calling in the right place the `fwpass` and `bwpass` functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfnyLsZxij0N"
      },
      "outputs": [],
      "source": [
        "def patchmatch (im1,im2,dmin,dmax,cw=7,it=5):\n",
        "    '''\n",
        "    computes the disparity map from im1 to im2 using the patchmatch\n",
        "    algorithm using the census cost\n",
        "\n",
        "    Args:\n",
        "        im1,im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin,dmax: minimum and maximum disparity to be explored\n",
        "        cw: census window size, used when cost='census'\n",
        "        it: iterations of the patchmatch algorithm\n",
        "    Returns:\n",
        "        numpy two arrays containing the disparity map and\n",
        "        the minimum matching costs at each pixel\n",
        "    '''\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    im1 = stereo.censustransform(im1,cw)\n",
        "    im2 = stereo.censustransform(im2,cw)\n",
        "    if im1.ndim == 2:   # stereo.computeHamming expects 3 dimensions\n",
        "        im1 = np.expand_dims(im1,2)\n",
        "        im2 = np.expand_dims(im2,2)\n",
        "    print ('t={:2.4f} done computing transforms {}, '.format(time.time() - start_time, im1.shape))\n",
        "\n",
        "    H,W,C = im1.shape\n",
        "    off    = np.zeros((H,W),dtype=np.float64)\n",
        "    cost   = np.zeros((H,W),dtype=np.float64) + np.Infinity\n",
        "\n",
        "    # iterate it times\n",
        "    for it in range(it):\n",
        "        newoff = np.random.randint(dmin,dmax,size=(H,W))\n",
        "        off, cost = randpass(off,cost,newoff,im1, im2)\n",
        "\n",
        "\n",
        "        ### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "    print ('t={:2.4f} done running patchmatch {}, '.format(time.time() - start_time, im1.shape))\n",
        "    return off, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1n3HA54ij0O"
      },
      "source": [
        "The code below tests the `patchmatch` algorithm (which uses your `fwpass` and `bwpass` functions).\n",
        "The algorithm will run 3 iterations, sampling about 15 disparities per pixel.\n",
        "The resulting disparities are then filtered applying the `mismatchFiltering` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvzGTa0kij0O"
      },
      "outputs": [],
      "source": [
        "#im1 = utils.readGTIFF('data/rectified_ref.tif')[:,:,0]\n",
        "#im2 = utils.readGTIFF('data/rectified_sec.tif')[:,:,0]\n",
        "#dmin,dmax=-100,150\n",
        "\n",
        "im1 = utils.readGTIFF('data/im2.png')#[:,:,0]\n",
        "im2 = utils.readGTIFF('data/im6.png')#[:,:,0]\n",
        "dmin,dmax = -60, 0\n",
        "\n",
        "# compute left and right disparity maps\n",
        "off,cost = patchmatch(im1,im2,dmin,dmax,11,3)\n",
        "offR,costR = patchmatch(im2,im1,-dmax,-dmin,11,3)\n",
        "\n",
        "# apply mismatch filtering\n",
        "LRS = mismatchFiltering(off, offR, 50, 3)\n",
        "# display result\n",
        "vistools.display_imshow(off, cmap='jet',range=[dmin,dmax], title='left patchmatch disparity', inline=True)\n",
        "vistools.display_imshow(offR, cmap='jet',range=[-dmax,-dmin], title='right patchmatch disparity', inline=True)\n",
        "print('Left-right consistent matches')\n",
        "vistools.display_imshow(LRS, cmap='jet',range=[dmin,dmax], title='filtered mismatches patchmatch disparity', inline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfyDO2Mqij0O"
      },
      "source": [
        "# G. Connecting the dots with the previous session\n",
        "\n",
        "Now let's compute the disparity map for a rectified stereo pair produced in the the TP-rectification.\n",
        "\n",
        "We first select the images and set the coordinates of the aoi.\n",
        "Then use the function `rectify.rectify_aoi` to generate the rectified crops to be passed to the stereo matching algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct-7c3Feij0O"
      },
      "outputs": [],
      "source": [
        "# list of tiff images available in the remote folder\n",
        "images = utils.find('http://menthe.ovh.hw.ipol.im/IARPA_data/cloud_optimized_geotif/', 'TIF')\n",
        "# sort the images by acquisition date\n",
        "images.sort(key=utils.acquisition_date)\n",
        "\n",
        "\n",
        "# create a map\n",
        "m = vistools.clickablemap()\n",
        "\n",
        "# select two image indices\n",
        "i, j = 37, 38\n",
        "\n",
        "# display the footprint polygons\n",
        "for k in [i, j]:\n",
        "    footprint = utils.lon_lat_image_footprint(images[k])\n",
        "    m.add_layer(ipyleaflet.GeoJSON(data=footprint))\n",
        "\n",
        "# center the map on the center of the last footprint\n",
        "m.center = np.mean(footprint['coordinates'][0][:4], axis=0).tolist()[::-1]\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnC_RA9Zij0O"
      },
      "source": [
        "Draw a (small) area of interest (AOI) within the images footprints on the image above. Then click on the \"Export\" button. This triggers the download of a file named `data.geojson` containing the definition of your AOI. Copy the content of this file and paste it in the cell below to define the variable `geojson_content`.\n",
        "\n",
        "If you don't, the default polygon defined in the next cell will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1u4Zosvij0O"
      },
      "outputs": [],
      "source": [
        "try:  # get coordinates of last AOI drawn on the map\n",
        "    aoi = m.AOIs[-1]\n",
        "\n",
        "except IndexError:  # predefined polygon on Buenos Aires if nothing was drawn\n",
        "    print(\"Failed geojson parsing. Using default AOI.\")\n",
        "    aoi = {'type': 'Polygon',\n",
        "           'coordinates': [[[-58.584587, -34.490861],\n",
        "                            [-58.584587, -34.489077],\n",
        "                            [-58.58301,  -34.489077],\n",
        "                            [-58.58301,  -34.490861],\n",
        "                            [-58.584587, -34.490861]]]}\n",
        "\n",
        "print(\"Selected polygon:\")\n",
        "pprint.pprint(aoi)\n",
        "\n",
        "# add center field\n",
        "aoi['center'] = np.mean(aoi['coordinates'][0][:4], axis=0).tolist()\n",
        "\n",
        "# draw the polygon and center map\n",
        "m.add_layer(ipyleaflet.GeoJSON(data=aoi))\n",
        "m.center = aoi['center'][::-1]\n",
        "m.zoom = m.zoom+2\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28OqmgUwij0O"
      },
      "outputs": [],
      "source": [
        "# apply the rectification\n",
        "import srtm4\n",
        "z = srtm4.srtm4(*aoi['center'])\n",
        "rect1, rect2, S1, S2, dmin, dmax, _, _ = rectification.rectify_aoi(images[i], images[j],\n",
        "                                                                   aoi, z=z, register_ground=True)\n",
        "\n",
        "# round the estimated disparity range (it might be under-estimated)\n",
        "dmin, dmax = int(np.floor(dmin))-15, int(np.ceil(dmax))+5\n",
        "print(\"disparity range: \", [dmin, dmax])\n",
        "\n",
        "# display the rectifies crops\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(rect1),\n",
        "                          utils.simple_equalization_8bit(rect2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NIfyrbNij0O"
      },
      "source": [
        "# Let's try the patchmatch algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y1DMoSZij0P"
      },
      "outputs": [],
      "source": [
        "im1, im2 = rect1, rect2\n",
        "cw = 13\n",
        "#dmin,dmax=-100,100\n",
        "dL, cost = patchmatch(im1, im2, dmin, dmax, cw, 3)\n",
        "dR, costR = patchmatch(im2, im1, -dmax, -dmin, cw, 3)\n",
        "\n",
        "# apply mismatch filtering\n",
        "LRSpm = mismatchFiltering(dL, dR, 50)\n",
        "\n",
        "# display the result\n",
        "#vistools.display_imshow(LRSpm, cmap='jet',range=[dmin,dmax])\n",
        "\n",
        "LRSpm[LRSpm==np.inf] = dmin\n",
        "vistools.display_imshow(LRSpm, cmap='jet',range=[dmin,dmax], inline=True)\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(LRSpm),\n",
        "                          utils.simple_equalization_8bit(rect1),\n",
        "                          utils.simple_equalization_8bit(rect2)\n",
        "                         ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxqkqggMij0P"
      },
      "source": [
        "# Now let's try SGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASvmbUCKij0P"
      },
      "outputs": [],
      "source": [
        "im1, im2 = rect1, rect2\n",
        "\n",
        "# some reasonable parameters\n",
        "lam = 10  # lambda is a parameter\n",
        "cw  = 5   # small census windows are good\n",
        "win = 3   # this removes some streaking artifacts\n",
        "\n",
        "# compute left and right disparity maps\n",
        "dL = stereoSGM(im1, im2, dmin, dmax, lam=lam, cost='census', cw=cw, win=win, subpix_refine=True)\n",
        "dR = stereoSGM(im2, im1, -dmax, -dmin, lam=lam, cost='census', cw=cw, win=win, subpix_refine=True)\n",
        "\n",
        "# apply mismatch filtering\n",
        "LRS = mismatchFiltering(dL, dR, 50)\n",
        "\n",
        "# display the result\n",
        "#vistools.display_imshow(LRS, cmap='jet',range=[dmin, dmax], inline=True)\n",
        "\n",
        "LRS[LRS==np.inf] = dmin\n",
        "vistools.display_imshow(LRS, cmap='jet',range=[dmin,dmax], inline=True)\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(LRS),\n",
        "                          utils.simple_equalization_8bit(rect1),\n",
        "                          utils.simple_equalization_8bit(rect2)\n",
        "                         ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fQi6DV7DY4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vTp1VOAij0P"
      },
      "source": [
        "# H. Subpixel refinement\n",
        "\n",
        "**Exercise 11.** Your keen eye might have spotted that the functions `stereoSGM` and `stereoBM` have an unused parameter `subpix_refine=False`.  **Briefly explain what it does. (look into the code)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>> YOUR ANSWER HERE"
      ],
      "metadata": {
        "id": "acyfpZfpWxR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G. Data Driven Methods\n",
        "\n",
        "\n",
        "<img src=\"https://media.makeameme.org/created/just-a-pinch-fb9d5ea96d.jpg\" alt=\"Deeplearning\" width=\"150px\"/>\n",
        "\n",
        "In this section we study two CNN-based stereo matching architectures:\n",
        "* **MCCNN:** *Stereo matching by training a convolutional neural network to compare image patches.* J. Zbontar, Y. LeCun. IJLR 2016\n",
        "* **PSMNet:** *Pyramid stereo matching network.* J.R. Chang, Y.S. Chen. CVPR 2018\n",
        "\n",
        "The first is essentially local as it just computes matching scores between image patches, while the second is an end-to-end multi-scale method.\n",
        "\n",
        "Data driven methods are trained on application specific datasets. These architectures were finetuned using satellite and aerial imagery in these two works:  \n",
        "* *Evaluation of MC-CNN Based Stereo Matching Pipeline for the CO3D Earth Observation Program.* Defonte, et al. IGARSS 2021.\n",
        "* *A new stereo dense matching benchmark dataset for deep learning.* Wu, et al. ISPRS 2021.\n",
        "\n",
        "The functions below allow to call these methods and to select among  pretrained weights proposed by the authors of the above methods. However, some care must be taken with the range of the inputs. Indeed some methods do not work with arbitrary disparity ranges, thus some precautions must be taken.\n"
      ],
      "metadata": {
        "id": "q8uhpxPE_cW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## MCCNN\n",
        "\n",
        "MCCNN is a method for computing a matching cost between patches. Its approach is to compute a similarity measure on small image patches using a convolutional neural network. Features are first comptuted on the images separately, then the correspondences are computed by comparing these representations.  Training is carried out in a supervised manner with a contrastive loss using similar and dissimilar pairs of patches. Two network architectures are proposed for this task: one tuned for speed, the other for accuracy.\n",
        "\n",
        "**Note that MCCNN produces a cost volume.**\n",
        "\n",
        "\n",
        "*Code based on \"Evaluation of MC-CNN Based Stereo Matching Pipeline for the CO3D Earth Observation Program.\" V. Defonte et al. IGARSS, 2021.*\n",
        "\n",
        "```python\n",
        "def stereoMCCNN(im1, im2, dmin, dmax, arch='fast', training_dataset='dfc', subpix_refine=False, returnCostVolume=False):\n",
        "    \"\"\"\n",
        "    Compute the disparity map from im1 to im2 using the MC-CNN algorithm [Zbontar, Lecun 2016]\n",
        "    reimplemented in the package MCCNN [Delfonte et al 2021]\n",
        "\n",
        "    Args:\n",
        "        im1, im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "        dmin, dmax (ints): minimum and maximum disparity to be explored\n",
        "        arch (str): use the 'fast' or 'accurate' architectures (default 'fast')\n",
        "        training_dataset (str): use weights trained with 'middlebury' or 'dfc' (data fusion contest) datasets (default 'dfc')\n",
        "        subpix_refine (bool): activates the Vfit subpixel refinement (default False)\n",
        "        returnCostVolume (bool): if set returns the cost volume insted of the disparity (default False)\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the disparity map\n",
        "    \"\"\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "I3sOprRBG61o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run mccnn\n",
        "from mccnn import stereoMCCNN\n",
        "disp = stereoMCCNN(im1, im2, dmin, dmax, arch=\"fast\", training_dataset=\"dfc\", subpix_refine=True)\n",
        "\n",
        "\n",
        "vistools.display_imshow(disp, cmap='jet',range=[dmin,dmax], inline=True)\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(im1,0),\n",
        "                          utils.simple_equalization_8bit(disp,0)\n",
        "                         ])"
      ],
      "metadata": {
        "id": "pw2c_-d_OJ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PSMNet\n",
        "\n",
        "Patch comparison methods such as MCCNN lack the means to exploit context information for finding correspondence in illposed regions. To tackle this problem PSMNet defines a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision.\n",
        "\n",
        "*Code based on \"Disparity Estimation Networks for Aerial and High-Resolution Satellite Images: A Review\". R. Marí et al. IPOL, 2022.*\n",
        "\n",
        "```python\n",
        "def stereoPSMNet(im1, im2, dmax, training_dataset='aerial'):\n",
        "    \"\"\"\n",
        "    Compute the disparity map from im1 to im2 using the PSMNet algorithm [Chang, Chen, 2018]\n",
        "    using the retrained weights from [Wu et al., 2021]\n",
        "\n",
        "    Args:\n",
        "        im1, im2: numpy arrays containing the stereo pair (im1 is reference)\n",
        "                  with float values normalized to the range [0,1]\n",
        "        dmax (ints): maximum disparity to be explored (no negative values)\n",
        "        training_dataset (str): use weights trained with \"kitti2012\", \"kitti2015\",\n",
        "               \"sceneflow\" and \"aerial\" (Aerial Stereo Dense Matching Benchmark)\n",
        "               datasets (default 'aerial')\n",
        "\n",
        "    Returns:\n",
        "        numpy array containing the disparity map\n",
        "    \"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-xLzkoc7p85S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run PSNNet\n",
        "from psm import stereoPSMNet\n",
        "a = utils.simplest_color_balance_8bit(im1,0)/255\n",
        "b = utils.simplest_color_balance_8bit(im2,0)/255\n",
        "dispPSM = - stereoPSMNet(a, b, 64, training_dataset='aerial')\n",
        "\n",
        "\n",
        "\n",
        "vistools.display_imshow(dispPSM, cmap='jet',range=[dmin,dmax], inline=True)\n",
        "vistools.display_gallery([utils.simple_equalization_8bit(im1,0),\n",
        "                          utils.simple_equalization_8bit(dispPSM,0)\n",
        "                         ])\n"
      ],
      "metadata": {
        "id": "b4jBINJNOVFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 12.** Use the provided functions to build a comparison of the three methods: SGM+Census, MCCNN, and PSMNet. Examples of aspects that can be relevant:\n",
        "- If ground truth is available, counting the number of piexels with error below a threshold\n",
        "- Without ground truth, count the consistency pixels (after applying the left-right test)\n",
        "- Qualitatively assess the reconstruction of edges, flat objects, untextured areas, small structures, handling of occluded pixels ...\n",
        "- Robustness to deformations and local contrast changes\n",
        "- Processing time\n",
        "- ..."
      ],
      "metadata": {
        "id": "fvgDBuD34Cxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>> WRITE YOUR ANSWER TO THE QUESTION HERE <<<"
      ],
      "metadata": {
        "id": "G_BxNgMu519i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 13.** Improve MCCNN by combining it with a cost volume filtering technique. **Then evaluate its results.**"
      ],
      "metadata": {
        "id": "mfOmDU0V5vfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    ### YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "f07zccnvAYXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A847wfLij0P"
      },
      "source": [
        "---------------------------\n",
        "[//]: # (© 2018 Gabriele Facciolo)\n",
        "[//]: # (<div style=\"text-align:center; font-size:75%;\"> Copyright © 2018 Gabriele Facciolo. All rights reserved.</div> )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}